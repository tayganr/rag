{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Text Chunking and Embedding with Azure OpenAI  \n",
    "\n",
    "In this notebook, we will process raw text data to prepare it for indexing in Azure AI Search. This involves several steps including loading the raw text data, chunking it into manageable pieces, generating embeddings for each chunk using a pre-trained model, and saving the chunked and embedded text into JSON files. These JSON files will be used in the subsequent notebook to create and populate an Azure AI Search index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 1.1 Import Libraries and Load Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv('.env')\n",
    "\n",
    "# Retrieve Azure OpenAI Service details from environment variables\n",
    "azure_openai_endpoint = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "azure_openai_key = os.getenv('AZURE_OPENAI_KEY')\n",
    "azure_openai_embedding_model = os.getenv('AZURE_OPENAI_EMBEDDING_MODEL_NAME')\n",
    "azure_openai_embedding_deployment = os.getenv('AZURE_OPENAI_EMBEDDING_DEPLOYMENT')\n",
    "azure_openai_api_version = os.getenv('AZURE_OPENAI_API_VERSION')\n",
    "\n",
    "# Initialize Azure OpenAI client\n",
    "client = AzureOpenAI(\n",
    "    azure_deployment=azure_openai_embedding_deployment,\n",
    "    api_version=azure_openai_api_version,\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    api_key=azure_openai_key\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read text files from a folder\n",
    "def read_text_files(folder_path):\n",
    "    text_files = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.txt'):\n",
    "            with open(os.path.join(folder_path, file_name), 'r', encoding='utf-8') as file:\n",
    "                text_files.append((file_name, file.read()))\n",
    "    return text_files\n",
    "\n",
    "# Function to chunk text using LangChain\n",
    "def chunk_text(text):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=0\n",
    "    )\n",
    "    return text_splitter.split_text(text)\n",
    "\n",
    "# Function to get embeddings using Azure OpenAI Service\n",
    "def get_embeddings(text_chunks):\n",
    "    embeddings = []\n",
    "    for chunk in text_chunks:\n",
    "        response = client.embeddings.create(input=[chunk], model=azure_openai_embedding_model)\n",
    "        embeddings.append(response.data[0].embedding)\n",
    "    return embeddings\n",
    "\n",
    "# Function to save results to a JSON file\n",
    "def save_to_json(file_name, chunked_data, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    output_path = os.path.join(output_folder, file_name.replace('.txt', '.json'))\n",
    "    with open(output_path, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(chunked_data, json_file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Process Each Text File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define folder paths\n",
    "documents_folder = 'documents'\n",
    "embeddings_folder = 'embeddings'\n",
    "\n",
    "# Read text files from the documents folder\n",
    "text_files = read_text_files(documents_folder)\n",
    "\n",
    "# Process each text file\n",
    "for file_name, text in text_files:\n",
    "    # Chunk the text\n",
    "    text_chunks = chunk_text(text)\n",
    "\n",
    "    # Get embeddings for each chunk\n",
    "    chunk_embeddings = get_embeddings(text_chunks)\n",
    "\n",
    "    # Prepare data for saving\n",
    "    chunked_data = [{\n",
    "        'chunk_id': idx,\n",
    "        'chunk_text': chunk,\n",
    "        'chunk_embedding': embedding\n",
    "    } for idx, (chunk, embedding) in enumerate(zip(text_chunks, chunk_embeddings))]\n",
    "\n",
    "    # Save the chunked data and embeddings to a JSON file\n",
    "    save_to_json(file_name, chunked_data, embeddings_folder)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
